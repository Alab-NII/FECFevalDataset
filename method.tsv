0	The choice of related pairs in this dataset was drawn from VCL in the following way.	These features were only included in our second run yiGou-midbaitu.	Singular value decomposition (SVD) is traditionally used to perform this factorization.	was drawn from	only included in	traditionally	Criteria for selection	Methodology used in past work	N18-2032_s-8-1-0-0	S15-2014_s-8-10-1-5	D13-1090_s-4-1-0-3	0.8
1	The predictors described above were selected for inclusion in a larger ensemble on the basis of their performance on the development set.	The choice of related pairs in this dataset was drawn from VCL in the following way.	The judges were asked to draw lines between matching sentences.	selected * on the basis of	was drawn from	were asked to	Criteria for selection	Description of the process	S15-2002_s-8-1-0-0	N18-2032_s-8-1-0-0	J93-1004_s-7-1-1-3	0.8
2	These features were only included in our second run yiGou-midbaitu.	The choice of related pairs in this dataset was drawn from VCL in the following way.	In this paper, the distortion probability in equation (2) is estimated during decoding, using the same method as described in Pharaoh (CITE-p-21-1-10).	only included in	was drawn from	using the same method as	Criteria for selection	Using methods used in past work	S15-2014_s-8-10-1-5	N18-2032_s-8-1-0-0	D07-1030_s-6-1-1-0	1
3	Inclusion criteria for the control group were elderlies with no cognitive deficits and preservation of functional capacity in everyday life.	These features were only included in our second run yiGou-midbaitu.	The first dataset called LabWriting consists of 93 patients with schizophrenia who were recruited from sites in both Washington, D.C. and New York City.	inclusion criteria	only included in	were recruited from	Criteria for selection	Characteristics of samples or data	P17-1118_s-8-4-0-2	S15-2014_s-8-10-1-5	S17-1028_s-4-1-0-0	0.6
4	We established the following criteria for selecting textbooks and texts:	These features were only included in our second run yiGou-midbaitu.	This rather large window size was employed since the sample sizes for each word were relatively small, often no more than a few hundred instances.	criteria for selecting	only included in	was employed since	Criteria for selection	Reasons why a method was adopted or rejected	E09-3003_s-4-1-3-2	S15-2014_s-8-10-1-5	S07-1087_s-3-4-1-2	0.8
5	For each set, we assign labels to the extracted subtrees according to their frequencies by using the same method as that of CITE-p-28-1-4.	Our CNN implementation is based on the architecture proposed by CITE-p-12-1-4.	A well-established approach in language modelling is the linear interpolation of several models, i.e. computing the weighted average of the individual model probabilities.	using the same method as	based on * proposed by	a well-established approach in	Using methods used in past work	Methodology used in past work	D11-1007_s-14-4-0-3	S16-1043_s-4-1-0-0	E12-1055_s-4-1-0-0	1
6	Our CNN implementation is based on the architecture proposed by CITE-p-12-1-4.	Afterwards, according to the procedure proposed in (CITE-p-14-3-7), the domain-dependent logic expressions are generated in (d).	No children met the criteria for a language impairment, and there were no significant between-group differences in age or full-scale IQ.	based on * proposed by	according to the procedure	met the criteria	Using methods used in past work	Characteristics of samples or data	S16-1043_s-4-1-0-0	N18-1060_s-5-1-0-4	P15-2035_s-3-1-0-2	1
7	Afterwards, according to the procedure proposed in (CITE-p-14-3-7), the domain-dependent logic expressions are generated in (d).	Model 0 can be parsed by adapting standard top-down or bottom-up chart parsing techniques.	There are a number of methods for this purpose (CITE-p-14-1-7, CITE-p-14-3-4, CITE-p-14-1-6, CITE-p-14-1-19).	according to the procedure	by adapting	there are a number of methods	Using methods used in past work	Methodology used in past work	N18-1060_s-5-1-0-4	P10-1001_s-9-6-1-0	E17-1112_s-4-1-1-3	0.4
8	Model 0 can be parsed by adapting standard top-down or bottom-up chart parsing techniques.	Our CNN implementation is based on the architecture proposed by CITE-p-12-1-4.	We first discuss the feature set and then the algorithm.	by adapting	based on * proposed by	and then	Using methods used in past work	Description of the process	P10-1001_s-9-6-1-0	S16-1043_s-4-1-0-0	D10-1032_s-7-1-1-1	1
9	A well-established approach in language modelling is the linear interpolation of several models, i.e. computing the weighted average of the individual model probabilities.	Learning mechanisms for disambiguating word senses have a long tradition in the WSD field.	The verbs were selected from Levin's classes on the basis of our intuitive judgment that they are likely to be used with sufficient frequency to be found in the corpus we had available.	a well-established approach in	a long tradition	selected * on the basis of	Methodology used in past work	Criteria for selection	E12-1055_s-4-1-0-0	S01-1031_s-5-1-0-0	E99-1007_s-8-1-4-0	1
10	Several methods have been proposed for SMT using pivot languages.	Learning mechanisms for disambiguating word senses have a long tradition in the WSD field.	The choice of related pairs in this dataset was drawn from VCL in the following way.	methods have been proposed	a long tradition	was drawn from	Methodology used in past work	Criteria for selection	P15-2094_s-6-1-0-0	S01-1031_s-5-1-0-0	N18-2032_s-8-1-0-0	0.8
11	Backoff models have been used in a variety of ways in natural language processing, most notably in statistical language modeling.	Many methods exist for clustering, e.g., (CITE-p-15-1-0, CITE-p-15-1-4, CITE-p-15-1-21, CITE-p-15-1-11).	This removal was carried out on both the transcripts and audio.	in a variety of ways	methods exist	was carried out	Methodology used in past work	Description of the process	E06-1006_s-4-1-0-2	E06-1050_s-5-1-0-3	E17-1030_s-6-3-0-1	1
12	There are a number of methods to form the document-term matrix MATH-w-6-8-2-11.	Reuters-21578 6 is one of the most common testbeds for text categorization.	These features were only included in our second run yiGou-midbaitu.	there are a number of methods	one of the most common	only included in	Methodology used in past work	Criteria for selection	D10-1025_s-6-8-2-0	P06-1133_s-5-8-2-1	S15-2014_s-8-10-1-5	1
13	Singular value decomposition (SVD) is traditionally used to perform this factorization.	Learning mechanisms for disambiguating word senses have a long tradition in the WSD field.	This procedure is based on the WSD algorithm proposed by CITE-p-8-1-1.	traditionally	a long tradition	based on * proposed by	Methodology used in past work	Using methods used in past work	D13-1090_s-4-1-0-3	S01-1031_s-5-1-0-0	S07-1088_s-5-1-0-0	0.8
14	Two of the most popular methods to create such a mapping include: global matrix factorization and the local context window method.	Learning mechanisms for disambiguating word senses have a long tradition in the WSD field.	The choice of related pairs in this dataset was drawn from VCL in the following way.	the most popular methods	a long tradition	was drawn from	Methodology used in past work	Criteria for selection	S16-1144_s-8-1-0-2	S01-1031_s-5-1-0-0	N18-2032_s-8-1-0-0	1
15	Logical forms for other VNMAs have been developed along similar lines.	Many methods exist for clustering, e.g., (CITE-p-15-1-0, CITE-p-15-1-4, CITE-p-15-1-21, CITE-p-15-1-11).	Seven possible types of relationships between TREATMENT and DISEASE were identified.	have been developed	methods exist	were identified	Methodology used in past work	Description of the process	E03-1067_s-5-3-0-1	E06-1050_s-5-1-0-3	P04-1055_s-4-1-0-2	1
16	Many methods exist for clustering, e.g., (CITE-p-15-1-0, CITE-p-15-1-4, CITE-p-15-1-21, CITE-p-15-1-11).	Several methods have been proposed for SMT using pivot languages.	None of the participants analyzed here met the criteria for language impairment, and the two groups were selected so that there were no statistically significant differences (via two-tailed t-test) between the groups in chronological age, verbal IQ, and full scale IQ.	methods exist	methods have been proposed	met the criteria	Methodology used in past work	Characteristics of samples or data	E06-1050_s-5-1-0-3	P15-2094_s-6-1-0-0	P17-2006_s-4-1-0-2	1
17	One of the most well known is the lexicalized reordering model (CITE-p-23-1-16).	There are a number of methods and tools available to carry out this training of feature values.	For processing purposes, the corpus was divided into 3500 segments.	the most well-known	there are a number of methods	was divided into	Methodology used in past work	Characteristics of samples or data	E09-1043_s-16-1-0-1	P03-1040_s-13-5-5-1	D16-1017_s-4-1-2-0	1
18	Learning mechanisms for disambiguating word senses have a long tradition in the WSD field.	Singular value decomposition (SVD) is traditionally used to perform this factorization.	Afterwards, according to the procedure proposed in (CITE-p-14-3-7), the domain-dependent logic expressions are generated in (d).	a long tradition	traditionally	according to the procedure	Methodology used in past work	Using methods used in past work	S01-1031_s-5-1-0-0	D13-1090_s-4-1-0-3	N18-1060_s-5-1-0-4	1
19	Reuters-21578 6 is one of the most common testbeds for text categorization.	A number of techniques used for finding collocations and co-occurrences of words, such as mutual information, may well be used to search co-occurrence tendency between the question and the candidate answer in the Web.	The participants were recruited from the Gothenburg MCI study, which is a large longitudinal study on mild cognitive impairment (CITE-p-17-5-7).	one of the most common	a number of techniques	were recruited from	Methodology used in past work	Characteristics of samples or data	P06-1133_s-5-8-2-1	P02-1054_s-3-6-1-3	D17-1108_s-5-1-0-0	0.8
20	A number of techniques used for finding collocations and co-occurrences of words, such as mutual information, may well be used to search co-occurrence tendency between the question and the candidate answer in the Web.	Several methods have been proposed for SMT using pivot languages.	Our CNN implementation is based on the architecture proposed by CITE-p-12-1-4.	a number of techniques	methods have been proposed	based on * proposed by	Methodology used in past work	Using methods used in past work	P02-1054_s-3-6-1-3	P15-2094_s-6-1-0-0	S16-1043_s-4-1-0-0	1
21	The same approach was used to extract sentences with the false-friend sense of the partial cognate, only this time we used the false-friend English words.	As we will show, Sequential Monte Carlo (SMC) algorithms have a number of advantages in this setting: they permit the efficient computation of both the outer and inner expectations, they are trivially parallelizable, and the number of samples provides an intuitive tuning tradeoff between accuracy and speed.	Furthermore, we use a fixed random seed to enable replicability.	approach was used to	have a number of advantages	to enable	Reasons why a method was adopted or rejected	Description of the process	P06-1056_s-6-1-3-0	D13-1007_s-5-9-1-4	S18-1032_s-14-1-0-5	0.5
22	Frequency 25 was chosen because it is a medium frequency for all three word classes.	As we will show, Sequential Monte Carlo (SMC) algorithms have a number of advantages in this setting: they permit the efficient computation of both the outer and inner expectations, they are trivially parallelizable, and the number of samples provides an intuitive tuning tradeoff between accuracy and speed.	All data was annotated by 22 undergraduate and graduate students in various disciplines who were recruited for the task.	was chosen because	have a number of advantages	were recruited for	Reasons why a method was adopted or rejected	Characteristics of samples or data	E97-1015_s-4-2-1-1	D13-1007_s-5-9-1-4	P14-2064_s-3-3-1-1	1
23	The cutoff of 20% was chosen to allow a few variations for most phones.	Another advantage of this structure is that it allows us to find the ‘hidden fragments’.	The choice of related pairs in this dataset was drawn from VCL in the following way.	was chosen to	another advantage of	was drawn from	Reasons why a method was adopted or rejected	Criteria for selection	N09-3006_s-12-2-1-1	D10-1038_s-11-1-2-1	N18-2032_s-8-1-0-0	0.8
24	The advantages of the new formulation are summarized in Table 1.	One advantage of the RNN is that it considers the word order in the event expression, which can be important.	All the meetings in the AMI corpus are spoken in English, but over half the participants are nonnative speakers.	the advantages of	one advantage of	over half	Reasons why a method was adopted or rejected	Characteristics of samples or data	N04-2010_s-3-7-1-12	N18-1174_s-7-1-2-1	N10-1001_s-3-9-0-0	1
25	This rather large window size was employed since the sample sizes for each word were relatively small, often no more than a few hundred instances.	A major advantage of current BPM systems (as well as their support for database access and enterprise system integration etc.) is their graphical development and authoring environments.	Our CNN implementation is based on the architecture proposed by CITE-p-12-1-4.	was employed since	a major advantage of	based on * proposed by	Reasons why a method was adopted or rejected	Using methods used in past work	S07-1087_s-3-4-1-2	E06-2004_s-2-6-0-0	S16-1043_s-4-1-0-0	1
26	After an initial pilot annotation study, the following annotation policy was adopted to overcome common disagreements: (1) When the argument is a noun and it is part of a definite description then include the entire definite description.	Parsing: partsof-speech and constituency parsing using a shift-reduce parser 2 , which was selected for its speed over accuracy.	Singular value decomposition (SVD) is traditionally used to perform this factorization.	was adopted to	was selected for	traditionally	Reasons why a method was adopted or rejected	Methodology used in past work	P06-2104_s-4-3-0-2	S17-2108_s-5-5-5-1	D13-1090_s-4-1-0-3	1
27	A major advantage of current BPM systems (as well as their support for database access and enterprise system integration etc.) is their graphical development and authoring environments.	The benefit of this approach is that the calculation for merging two clusters depends only on coreference decisions between individual strings, which can be calculated independently.	Logical forms for other VNMAs have been developed along similar lines.	a major advantage of	the benefit of this approach	have been developed	Reasons why a method was adopted or rejected	Methodology used in past work	E06-2004_s-2-6-0-0	N07-1016_s-9-1-1-1	E03-1067_s-5-3-0-1	1
28	As we will show, Sequential Monte Carlo (SMC) algorithms have a number of advantages in this setting: they permit the efficient computation of both the outer and inner expectations, they are trivially parallelizable, and the number of samples provides an intuitive tuning tradeoff between accuracy and speed.	This rather large window size was employed since the sample sizes for each word were relatively small, often no more than a few hundred instances.	All data was annotated by 22 undergraduate and graduate students in various disciplines who were recruited for the task.	have a number of advantages	was employed since	were recruited for	Reasons why a method was adopted or rejected	Characteristics of samples or data	D13-1007_s-5-9-1-4	S07-1087_s-3-4-1-2	P14-2064_s-3-3-1-1	0.8
29	The benefit of this approach lies in its generalisation power: once a function between the two semantic spaces is learnt, it can be used to see how an unseen concept relates to other concepts, just by looking at an image of that concept.	This rather large window size was employed since the sample sizes for each word were relatively small, often no more than a few hundred instances.	In order to assess the quality of the guidelines and the annotation, we conducted an inter-annotator agreement study.	the benefit of this approach	was employed since	in order to assess	Reasons why a method was adopted or rejected	Description of the process	N16-1071_s-5-5-1-0	S07-1087_s-3-4-1-2	Q14-1042_s-4-9-1-0	0.8
30	Parsing: partsof-speech and constituency parsing using a shift-reduce parser 2 , which was selected for its speed over accuracy.	A logistic regression approach was used to classify the dialogue acts based on the above feature vectors.	These hashtags were selected on the basis of a nearest-neighbor search of the word embedding space.	was selected for	approach was used to	selected * on the basis of	Reasons why a method was adopted or rejected	Criteria for selection	S17-2108_s-5-5-5-1	P11-1119_s-15-1-0-0	S16-1074_s-7-3-1-1	0.25
31	One advantage of the discriminative method is that it enables us to incorporate arbitrary features.	The benefit of this approach is that the calculation for merging two clusters depends only on coreference decisions between individual strings, which can be calculated independently.	In recent years, several methods have been proposed for constructing kernels from trained probabilistic models.	one advantage of	the benefit of this approach	methods have been proposed	Reasons why a method was adopted or rejected	Methodology used in past work	D13-1026_s-8-1-0-0	N07-1016_s-9-1-1-1	P05-1023_s-3-1-0-0	1
32	Another advantage of this structure is that it allows us to find the ‘hidden fragments’.	Logistic regression was chosen because it produces a model with high performance and results that are easily interpretable.	Afterwards, according to the procedure proposed in (CITE-p-14-3-7), the domain-dependent logic expressions are generated in (d).	another advantage of	was chosen because	according to the procedure	Reasons why a method was adopted or rejected	Using methods used in past work	D10-1038_s-11-1-2-1	D13-1094_s-5-1-0-1	N18-1060_s-5-1-0-4	1
33	The main disadvantage of simple concatenation is that word embeddings are commonly used to initialize words in DNN systems; thus, the high-dimensionality of concatenated embeddings causes a great increase in training parameters.	Logistic regression was chosen because it produces a model with high performance and results that are easily interpretable.	Many methods exist for clustering, e.g., (CITE-p-15-1-0, CITE-p-15-1-4, CITE-p-15-1-21, CITE-p-15-1-11).	the main disadvantage of	was chosen because	methods exist	Reasons why a method was adopted or rejected	Methodology used in past work	P16-1128_s-6-4-1-3	D13-1094_s-5-1-0-1	E06-1050_s-5-1-0-3	1
34	Approval to analyze the dataset was obtained from the Stanford IRB.	Our tests were run without any selection of a subject area.	For each set, we assign labels to the extracted subtrees according to their frequencies by using the same method as that of CITE-p-28-1-4.	was obtained from	were run	using the same method as	Description of the process	Using methods used in past work	Q16-1033_s-4-5-1-5	E97-1015_s-8-3-7-0	D11-1007_s-14-4-0-3	0.4
35	Third, a subset of the resulting sentences were sent to a validation task aimed at providing a highly reliable set of annotations over the same data, and at identifying areas of inferential uncertainty.	To compare with prior work, we use different experimental settings.	A number of techniques used for finding collocations and co-occurrences of words, such as mutual information, may well be used to search co-occurrence tendency between the question and the candidate answer in the Web.	were sent	to compare	a number of techniques	Description of the process	Methodology used in past work	D15-1075_s-3-4-4-4	P17-1092_s-10-3-0-1	P02-1054_s-3-6-1-3	0.8
36	In order to assess the contribution of each group to the overall system performance, we performed a feature ablation experiment.	The pronunciations were generated using CMU Dictionary and later manually corrected.	This procedure is based on the WSD algorithm proposed by CITE-p-8-1-1.	in order to assess	were generated	based on * proposed by	Description of the process	Using methods used in past work	N13-1133_s-22-1-0-4	N07-2003_s-4-3-1-7	S07-1088_s-5-1-0-0	1
37	In order to understand the temporal nature of healthcare data, we need to develop deep learning models whose parameters gets incrementally updated with time.	Further, online reference lists of projects and authors concerned with manual annotations were searched.	Support vector machines (SVMs) are one of the most popular methods for text classification, largely because they can automatically weight large numbers of features, capturing feature interactions in the process (CITE-p-18-1-13, CITE-p-18-3-5).	in order to understand	were searched	the most popular methods	Description of the process	Methodology used in past work	P18-3005_s-8-3-5-3	J11-4004_s-5-1-0-4	N10-1027_s-9-1-0-0	0.8
38	Once these games were completed, we prioritized ordering based on object category to include a comprehensive range of objects.	The reward was set at $0.10 per translation, or roughly $0.005 per word.	Another advantage of the discriminative tagger is its relatively good prediction power of the longer-distance dependencies.	were completed	was set at	another advantage of	Description of the process	Reasons why a method was adopted or rejected	D14-1086_s-9-1-0-3	P11-1122_s-6-1-1-2	J16-3002_s-29-11-2-5	0.8
39	In order to control for this a bound on minimum pronunciation length can be utilized.	Questions were coded simply by the presence of question marks.	Logistic regression was chosen because it produces a model with high performance and results that are easily interpretable.	in order to control	were coded	was chosen because	Description of the process	Reasons why a method was adopted or rejected	N04-1017_s-7-3-1-3	N09-1072_s-8-4-1-3	D13-1094_s-5-1-0-1	0.6
40	All unigrams, bigrams, and trigrams were taken from each response.	In total, over 10,000 commands were collected through the game.	A major advantage of current BPM systems (as well as their support for database access and enterprise system integration etc.) is their graphical development and authoring environments.	were taken from	were collected	a major advantage of	Description of the process	Reasons why a method was adopted or rejected	P15-2016_s-5-1-0-1	S14-2006_s-6-1-0-0	E06-2004_s-2-6-0-0	1
41	The coreference feature value was calculated using clusters of coreferential entities.	Furthermore, we use a fixed random seed to enable replicability.	Model 0 can be parsed by adapting standard top-down or bottom-up chart parsing techniques.	was calculated using	to enable	by adapting	Description of the process	Using methods used in past work	S14-2139_s-5-3-1-1	S18-1032_s-14-1-0-5	P10-1001_s-9-6-1-0	0.5
42	Finally, we randomly pull 200 tweets for each identified user.	For this reason, it was necessary to employ validation in training.	Our CNN implementation is based on the architecture proposed by CITE-p-12-1-4.	finally	it was necessary to	based on * proposed by	Description of the process	Using methods used in past work	D16-1107_s-5-1-0-3	J03-1004_s-9-27-0-2	S16-1043_s-4-1-0-0	1
43	11 models were then interpolated to create one language model.	Paragraphs were identified based on formatting information available in the articles.	The first dataset called LabWriting consists of 93 patients with schizophrenia who were recruited from sites in both Washington, D.C. and New York City.	were then	were identified	were recruited from	Description of the process	Characteristics of samples or data	N07-2033_s-4-1-1-2	P11-2117_s-4-1-1-1	S17-1028_s-4-1-0-0	0.8
44	The input order is randomized, to prevent spurious order effects.	Using the above approach for Chinese-English, 185 candidate sites were searched from the domain hk.	A number of techniques used for finding collocations and co-occurrences of words, such as mutual information, may well be used to search co-occurrence tendency between the question and the candidate answer in the Web.	to prevent	were searched	a number of techniques	Description of the process	Methodology used in past work	P16-3010_s-8-1-1-1	A00-1004_s-9-1-0-0	P02-1054_s-3-6-1-3	0.6
45	The pronunciations were generated using CMU Dictionary and later manually corrected.	Six different surveys, each including approximately 50 stimulus words, were administered for each region.	Afterwards, according to the procedure proposed in (CITE-p-14-3-7), the domain-dependent logic expressions are generated in (d).	were generated	were administered	according to the procedure	Description of the process	Using methods used in past work	N07-2003_s-4-3-1-7	D17-1241_s-4-3-1-2	N18-1060_s-5-1-0-4	0.75
46	The first step was to identify the languages which are syntactically related to the surprise languages and whose treebanks are in Universal Dependency corpus.	After training, we can apply the resulting model to resolve AZPs.	This rather large window size was employed since the sample sizes for each word were relatively small, often no more than a few hundred instances.	the first step was to	after training	was employed since	Description of the process	Reasons why a method was adopted or rejected	K17-3019_s-5-3-1-0	D14-1084_s-10-1-0-0	S07-1087_s-3-4-1-2	0.6
47	We derived the test set from the user set in order to establish accuracies of our model over the application domain.	Compound splitting is performed on the training corpus, prior to training.	First, a Japanese lexical substitution dataset was constructed using the same method as CITE-p-22-3-1.	in order to establish	prior to	using the same method as	Description of the process	Using methods used in past work	N15-1044_s-5-1-0-4	E09-3008_s-7-7-1-3	P15-3006_s-7-1-0-1	0.6
48	The judges were asked to draw lines between matching sentences.	The coreference feature value was calculated using clusters of coreferential entities.	The data split was chosen to have minimal overlap between discriminant features.	were asked to	was calculated using	was chosen to	Description of the process	Reasons why a method was adopted or rejected	J93-1004_s-7-1-1-3	S14-2139_s-5-3-1-1	S18-1170_s-3-3-3-2	0.6
49	The sentences were coded by five crowdsourced workers and one expert.	In order to understand the temporal nature of healthcare data, we need to develop deep learning models whose parameters gets incrementally updated with time.	A well-established approach in language modelling is the linear interpolation of several models, i.e. computing the weighted average of the individual model probabilities.	were coded	in order to understand	a well-established approach in	Description of the process	Methodology used in past work	E17-2037_s-4-1-0-4	P18-3005_s-8-3-5-3	E12-1055_s-4-1-0-0	0.5
50	The number of latent dimensions for the SVD-reduced space was set at 300 after testing the performance using 300, 600 and 900 latent dimensions.	The first step was to identify the languages which are syntactically related to the surprise languages and whose treebanks are in Universal Dependency corpus.	Inclusion criteria for the control group were elderlies with no cognitive deficits and preservation of functional capacity in everyday life.	was set at	the first step was to	inclusion criteria	Description of the process	Criteria for selection	D12-1112_s-8-5-1-2	K17-3019_s-5-3-1-0	P17-1118_s-8-4-0-2	0.8
51	These statistics are calculated prior to consolidating multiple annotators’ work.	Users were asked to answer questions like “Do you smoke?”	The 79 subcategories were divided into training and testing segments.	prior to	were asked to	were divided into	Description of the process	Characteristics of samples or data	P16-1126_s-8-8-0-1	D17-1240_s-4-3-1-1	S12-1047_s-8-1-0-0	0.25
52	The experts could access the premises to see if unclear references can be resolved.	Note that all species words (e.g., Drosophila) were normalised to “SPECIESWORD”, and entities (e.g., Kip3) to “ENTITY”, which not only reduces the noise in the feature set, but also makes the model more species-generic.	For processing purposes, the corpus was divided into 3500 segments.	to see if	were normalised	was divided into	Description of the process	Characteristics of samples or data	E17-1105_s-13-6-1-0	D09-1157_s-9-3-1-8	D16-1017_s-4-1-2-0	0.25
53	The human ratings were gathered using the Magnitude Estimation technique (CITE-p-13-1-0).	Articles and summaries are paired by document, so the first step was to perform sentence alignment.	This procedure is based on the WSD algorithm proposed by CITE-p-8-1-1.	were gathered	the first step was to	based on * proposed by	Description of the process	Using methods used in past work	E06-1044_s-5-1-4-7	N07-1023_s-6-1-0-1	S07-1088_s-5-1-0-0	0.8
54	To increase their significance we double their raw count values.	For our experiments, the text was obtained from MEDLINE 2001 2 .	Slightly over half of the definitions have a length of 5–16 words; 75% have lengths between 3 and 23 words.	to increase	was obtained from	over half	Description of the process	Characteristics of samples or data	S18-1030_s-4-4-1-8	P04-1055_s-4-1-0-0	D13-1073_s-12-4-0-5	1
55	We first discuss the feature set and then the algorithm.	Dropout is then applied to these vectors prior to classification.	The benefit of this approach lies in its generalisation power: once a function between the two semantic spaces is learnt, it can be used to see how an unseen concept relates to other concepts, just by looking at an image of that concept.	and then	prior to	the benefit of this approach	Description of the process	Reasons why a method was adopted or rejected	D10-1032_s-7-1-1-1	S18-1185_s-4-5-0-0	N16-1071_s-5-5-1-0	1
56	We cleaned the corpus by applying a language detection tool (langdetect 2 ) to each sentence, in order to remove sentences which are too noisy.	After training, we can apply the resulting model to resolve AZPs.	The benefit of this approach is that the calculation for merging two clusters depends only on coreference decisions between individual strings, which can be calculated independently.	in order to remove	after training	the benefit of this approach	Description of the process	Reasons why a method was adopted or rejected	E17-4012_s-5-1-0-5	D14-1084_s-10-1-0-0	N07-1016_s-9-1-1-1	0.8
57	In order to measure the semantic similarity between tweets, rather than isolated words, we needed a way to obtain vector representations of documents.	Web queries were gathered from online sources of real-world queries.	There are a number of methods for this purpose (CITE-p-14-1-7, CITE-p-14-3-4, CITE-p-14-1-6, CITE-p-14-1-19).	in order to measure	were gathered	there are a number of methods	Description of the process	Methodology used in past work	S16-1072_s-7-1-1-0	S14-2003_s-7-1-1-8	E17-1112_s-4-1-1-3	0.8
58	For supertagging, experiments were run with the standard splits of CCGbank.	Negation relations were identified using the output of the dependency parser.	Only wordforms that did not appear in the first gold standard were included in the second one.	were run	were identified	were included in	Description of the process	Characteristics of samples or data	N16-1027_s-8-1-0-0	S14-2070_s-5-7-0-2	E09-1015_s-12-3-3-2	0.8
59	In total, over 10,000 commands were collected through the game.	For this reason, it was necessary to employ validation in training.	All data was annotated by 22 undergraduate and graduate students in various disciplines who were recruited for the task.	were collected	it was necessary to	were recruited for	Description of the process	Characteristics of samples or data	S14-2006_s-6-1-0-0	J03-1004_s-9-27-0-2	P14-2064_s-3-3-1-1	0.2
60	The experiments were performed on an i5, 2.8 GHz processor.	This is to prevent fatigue over a period of time.	Afterwards, according to the procedure proposed in (CITE-p-14-3-7), the domain-dependent logic expressions are generated in (d).	were performed	to prevent	according to the procedure	Description of the process	Using methods used in past work	D14-1171_s-4-10-0-6	P14-2007_s-5-6-2-2	N18-1060_s-5-1-0-4	0.2
61	Note that all species words (e.g., Drosophila) were normalised to “SPECIESWORD”, and entities (e.g., Kip3) to “ENTITY”, which not only reduces the noise in the feature set, but also makes the model more species-generic.	To increase their significance we double their raw count values.	Reuters-21578 6 is one of the most common testbeds for text categorization.	were normalised	to increase	one of the most common	Description of the process	Methodology used in past work	D09-1157_s-9-3-1-8	S18-1030_s-4-4-1-8	P06-1133_s-5-8-2-1	1
62	Keywords are used both in order to identify thematically relevant tweets and also targets.	Note that all species words (e.g., Drosophila) were normalised to “SPECIESWORD”, and entities (e.g., Kip3) to “ENTITY”, which not only reduces the noise in the feature set, but also makes the model more species-generic.	A larger set of Arabic Wikipedia articles, selected on the basis of quality heuristics, serves as unlabeled data for semisupervised learning.	in order to identify	were normalised	selected * on the basis of	Description of the process	Criteria for selection	E17-1046_s-5-1-0-6	D09-1157_s-9-3-1-8	E12-1017_s-7-1-0-3	0.6
63	Furthermore, we use a fixed random seed to enable replicability.	In order to identify such terms, we first extract all content terms from the query.	The criteria for selecting the next candidate sentence to annotate can then be described as: MATH-p-9-9-0 where MATH-p-9-11-0	to enable	in order to identify	criteria for selecting	Description of the process	Criteria for selection	S18-1032_s-14-1-0-5	P14-1115_s-6-1-0-1	P13-3011_s-9-8-1-0	0.8
64	An LR classifier was then trained over the labeled sentences.	Negative examples were generated by randomly shuffling the original set of 1385 pairs.	Afterwards, according to the procedure proposed in (CITE-p-14-3-7), the domain-dependent logic expressions are generated in (d).	was then	were generated	according to the procedure	Description of the process	Using methods used in past work	D15-1050_s-8-1-1-1	D16-1234_s-4-1-2-2	N18-1060_s-5-1-0-4	0.75
65	In order to determine the most probable phrase combination in network structure, heuristic rules axe applied.	The threshold was set at 200 words of automatically scraped body text of a linked document.	Model 0 can be parsed by adapting standard top-down or bottom-up chart parsing techniques.	in order to determine	was set at	by adapting	Description of the process	Using methods used in past work	P86-1024_s-6-10-0-0	D13-1142_s-5-1-0-4	P10-1001_s-9-6-1-0	0.8
66	The number of latent dimensions for the SVD-reduced space was set at 300 after testing the performance using 300, 600 and 900 latent dimensions.	In order to assess the quality of the guidelines and the annotation, we conducted an inter-annotator agreement study.	Several methods have been proposed for smoothing ME models (see CITE-p-7-1-3).	after testing	in order to assess	methods have been proposed	Description of the process	Methodology used in past work	D12-1112_s-8-5-1-2	Q14-1042_s-4-9-1-0	E03-1071_s-3-1-0-0	1
67	For this reason, it was necessary to employ validation in training.	The number of latent dimensions for the SVD-reduced space was set at 300 after testing the performance using 300, 600 and 900 latent dimensions.	However, the main disadvantage of this approach to estimate interlingual text similarity is that it strongly relies on the availability of a multilingual lexical resource.	it was necessary to	was set at	the main disadvantage of	Description of the process	Reasons why a method was adopted or rejected	J03-1004_s-9-27-0-2	D12-1112_s-8-5-1-2	P06-1070_s-5-1-0-2	1
68	Negation relations were identified using the output of the dependency parser.	Furthermore, we use a fixed random seed to enable replicability.	A larger set of Arabic Wikipedia articles, selected on the basis of quality heuristics, serves as unlabeled data for semisupervised learning.	were identified	to enable	selected * on the basis of	Description of the process	Criteria for selection	S14-2070_s-5-7-0-2	S18-1032_s-14-1-0-5	E12-1017_s-7-1-0-3	0.4
69	Six different surveys, each including approximately 50 stimulus words, were administered for each region.	In order to measure the semantic similarity between tweets, rather than isolated words, we needed a way to obtain vector representations of documents.	Model 0 can be parsed by adapting standard top-down or bottom-up chart parsing techniques.	were administered	in order to measure	by adapting	Description of the process	Using methods used in past work	D17-1241_s-4-3-1-2	S16-1072_s-7-1-1-0	P10-1001_s-9-6-1-0	0.8
70	Two separate tests were done, one to compare the means for each student individually, and one to compare the means across all students.	For this reason, it was necessary to employ validation in training.	Singular value decomposition (SVD) is traditionally used to perform this factorization.	to compare	it was necessary to	traditionally	Description of the process	Methodology used in past work	P11-3017_s-4-12-1-1	J03-1004_s-9-27-0-2	D13-1090_s-4-1-0-3	1
71	After training, the learned embedding matrices are ready to be used.	This removal was carried out on both the transcripts and audio.	Afterwards, according to the procedure proposed in (CITE-p-14-3-7), the domain-dependent logic expressions are generated in (d).	after training	was carried out	according to the procedure	Description of the process	Using methods used in past work	N18-2054_s-9-1-1-0	E17-1030_s-6-3-0-1	N18-1060_s-5-1-0-4	0.8
72	After collection, we get a set of instances MATH-w-6-1-2-101 with different document-topic distributions for each bilingual term pair.	The threshold was set at 200 words of automatically scraped body text of a linked document.	One of the most well known is the lexicalized reordering model (CITE-p-23-1-16).	after collection	was set at	the most well-known	Description of the process	Methodology used in past work	D14-1060_s-6-1-2-2	D13-1142_s-5-1-0-4	E09-1043_s-16-1-0-1	1
73	Further, online reference lists of projects and authors concerned with manual annotations were searched.	In total, over 10,000 commands were collected through the game.	After an initial pilot annotation study, the following annotation policy was adopted to overcome common disagreements: (1) When the argument is a noun and it is part of a definite description then include the entire definite description.	were searched	were collected	was adopted to	Description of the process	Reasons why a method was adopted or rejected	J11-4004_s-5-1-0-4	S14-2006_s-6-1-0-0	P06-2104_s-4-3-0-2	0.6
74	This removal was carried out on both the transcripts and audio.	The dataset was obtained from a previous study conducted by the authors.	None of the participants analyzed here met the criteria for language impairment, and the two groups were selected so that there were no statistically significant differences (via two-tailed t-test) between the groups in chronological age, verbal IQ, and full scale IQ.	was carried out	was obtained from	met the criteria	Description of the process	Characteristics of samples or data	E17-1030_s-6-3-0-1	P17-1131_s-4-1-0-1	P17-2006_s-4-1-0-2	0.5
75	The corpus was divided into training (75%) and testing (25%) sets.	None of the participants analyzed here met the criteria for language impairment, and the two groups were selected so that there were no statistically significant differences (via two-tailed t-test) between the groups in chronological age, verbal IQ, and full scale IQ.	For supertagging, experiments were run with the standard splits of CCGbank.	was divided into	met the criteria	were run	Characteristics of samples or data	Description of the process	N06-3006_s-5-4-1-0	P17-2006_s-4-1-0-2	N16-1027_s-8-1-0-0	0.6
76	Only wordforms that did not appear in the first gold standard were included in the second one.	The first dataset called LabWriting consists of 93 patients with schizophrenia who were recruited from sites in both Washington, D.C. and New York City.	We established the following criteria for selecting textbooks and texts:	were included in	were recruited from	criteria for selecting	Characteristics of samples or data	Criteria for selection	E09-1015_s-12-3-3-2	S17-1028_s-4-1-0-0	E09-3003_s-4-1-3-2	0.8
77	All data was annotated by 22 undergraduate and graduate students in various disciplines who were recruited for the task.	For each concept, the preferred term as well as the synonyms were included in the dictionary.	Many methods exist for clustering, e.g., (CITE-p-15-1-0, CITE-p-15-1-4, CITE-p-15-1-21, CITE-p-15-1-11).	were recruited for	were included in	methods exist	Characteristics of samples or data	Methodology used in past work	P14-2064_s-3-3-1-1	S15-2064_s-5-1-1-3	E06-1050_s-5-1-0-3	1
78	The participants were recruited from the Gothenburg MCI study, which is a large longitudinal study on mild cognitive impairment (CITE-p-17-5-7).	No children met the criteria for a language impairment, and there were no significant between-group differences in age or full-scale IQ.	After collection, we get a set of instances MATH-w-6-1-2-101 with different document-topic distributions for each bilingual term pair.	were recruited from	met the criteria	after collection	Characteristics of samples or data	Description of the process	D17-1108_s-5-1-0-0	P15-2035_s-3-1-0-2	D14-1060_s-6-1-2-2	0.4
79	All the meetings in the AMI corpus are spoken in English, but over half the participants are nonnative speakers.	The 79 subcategories were divided into training and testing segments.	First, a Japanese lexical substitution dataset was constructed using the same method as CITE-p-22-3-1.	over half	were divided into	using the same method as	Characteristics of samples or data	Using methods used in past work	N10-1001_s-3-9-0-0	S12-1047_s-8-1-0-0	P15-3006_s-7-1-0-1	0.8
80	They were divided into four groups, which received 1, 2, 4 or 8 sets of words.	Only wordforms that did not appear in the first gold standard were included in the second one.	A major advantage of current BPM systems (as well as their support for database access and enterprise system integration etc.) is their graphical development and authoring environments.	were divided into	were included in	a major advantage of	Characteristics of samples or data	Reasons why a method was adopted or rejected	D15-1134_s-3-7-4-1	E09-1015_s-12-3-3-2	E06-2004_s-2-6-0-0	1
81	None of the participants analyzed here met the criteria for language impairment, and the two groups were selected so that there were no statistically significant differences (via two-tailed t-test) between the groups in chronological age, verbal IQ, and full scale IQ.	All data was annotated by 22 undergraduate and graduate students in various disciplines who were recruited for the task.	A larger set of Arabic Wikipedia articles, selected on the basis of quality heuristics, serves as unlabeled data for semisupervised learning.	met the criteria	were recruited for	selected * on the basis of	Characteristics of samples or data	Criteria for selection	P17-2006_s-4-1-0-2	P14-2064_s-3-3-1-1	E12-1017_s-7-1-0-3	0.4
