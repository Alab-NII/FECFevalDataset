method	Methodology used in past work	the most well-known	One of the most well known is the lexicalized reordering model (CITE-p-23-1-16).
method	Methodology used in past work	the most well-known	TextRank (Mihalcea and Tarau, 2004) is one of the most well-known graph-based approaches to keyphrase extraction.
method	Methodology used in past work	the most well-known	These techniques are now relatively standard; the most well-known approach involves junction trees (Pearl, 1988; Cowell, 1999).
method	Methodology used in past work	traditionally	Singular value decomposition (SVD) is traditionally used to perform this factorization.
method	Methodology used in past work	a number of techniques	A number of techniques used for finding collocations and co-occurrences of words, such as mutual information, may well be used to search co-occurrence tendency between the question and the candidate answer in the Web.
method	Methodology used in past work	methods have been proposed	Several methods have been proposed for SMT using pivot languages.
method	Methodology used in past work	methods have been proposed	Several semantic textual similarity (STS) methods have been proposed in literature.
method	Methodology used in past work	methods have been proposed	Several methods have been proposed for smoothing ME models (see CITE-p-7-1-3).
method	Methodology used in past work	methods have been proposed	In recent years, several methods have been proposed for constructing kernels from trained probabilistic models.
method	Methodology used in past work	in a variety of ways	Contexts can be represented in a variety of ways, from unordered bags of words to rich syntactic structures.
method	Methodology used in past work	in a variety of ways	Backoff models have been used in a variety of ways in natural language processing, most notably in statistical language modeling.
method	Methodology used in past work	methods exist	Many methods exist for clustering, e.g., (CITE-p-15-1-0, CITE-p-15-1-4, CITE-p-15-1-21, CITE-p-15-1-11).
method	Methodology used in past work	one of the most common	Reuters-21578 6 is one of the most common testbeds for text categorization.
method	Methodology used in past work	one of the most common	One of the most common evaluation methods consists of comparing automatic summaries with other summaries.
method	Methodology used in past work	one of the most common	One of the most common model training methods for supervised dependency parser is Maximum conditional likelihood estimation.
method	Methodology used in past work	one of the most common	The Automatic Content Extraction (ACE) Corpus (CITE-p-19-1-6) is one of the most common corpora for performing relation extraction.
method	Methodology used in past work	a long tradition	Learning mechanisms for disambiguating word senses have a long tradition in the WSD field.
method	Methodology used in past work	there are a number of methods	There are a number of methods and tools available to carry out this training of feature values.
method	Methodology used in past work	there are a number of methods	There are a number of methods to form the document-term matrix MATH-w-6-8-2-11.
method	Methodology used in past work	there are a number of methods	There are a number of methods for this purpose (CITE-p-14-1-7, CITE-p-14-3-4, CITE-p-14-1-6, CITE-p-14-1-19).
method	Methodology used in past work	the most popular methods	Finite-state networks are currently one of the most popular methods in computational morphology.
method	Methodology used in past work	the most popular methods	Two of the most popular methods to create such a mapping include: global matrix factorization and the local context window method.
method	Methodology used in past work	the most popular methods	Support vector machines (SVMs) are one of the most popular methods for text classification, largely because they can automatically weight large numbers of features, capturing feature interactions in the process (CITE-p-18-1-13, CITE-p-18-3-5).
method	Methodology used in past work	have been developed	Text prediction methods have been developed for several different purposes.
method	Methodology used in past work	have been developed	Logical forms for other VNMAs have been developed along similar lines.
method	Methodology used in past work	have been developed	In addition, specific strategies have been developed to deal with negative answers.
method	Methodology used in past work	have been developed	Various algorithms for unsupervised parsing have been developed in the past decades.
method	Methodology used in past work	a well-established approach in	A well-established approach in language modelling is the linear interpolation of several models, i.e. computing the weighted average of the individual model probabilities.
method	Reasons why a method was adopted or rejected	a major advantage of	A major advantage of current BPM systems (as well as their support for database access and enterprise system integration etc.) is their graphical development and authoring environments.
method	Reasons why a method was adopted or rejected	the benefit of this approach	The benefit of this approach is that the calculation for merging two clusters depends only on coreference decisions between individual strings, which can be calculated independently.
method	Reasons why a method was adopted or rejected	the benefit of this approach	The benefit of this approach lies in its generalisation power: once a function between the two semantic spaces is learnt, it can be used to see how an unseen concept relates to other concepts, just by looking at an image of that concept.
method	Reasons why a method was adopted or rejected	was selected for	Parsing: partsof-speech and constituency parsing using a shift-reduce parser 2 , which was selected for its speed over accuracy.
method	Reasons why a method was adopted or rejected	approach was used to	A logistic regression approach was used to classify the dialogue acts based on the above feature vectors.
method	Reasons why a method was adopted or rejected	approach was used to	The same approach was used to extract sentences with the false-friend sense of the partial cognate, only this time we used the false-friend English words.
method	Reasons why a method was adopted or rejected	was employed since	This rather large window size was employed since the sample sizes for each word were relatively small, often no more than a few hundred instances.
method	Reasons why a method was adopted or rejected	was chosen because	Frequency 25 was chosen because it is a medium frequency for all three word classes.
method	Reasons why a method was adopted or rejected	was chosen because	Reverse order was chosen because clinical documents often close with a final (and informative) diagnosis.
method	Reasons why a method was adopted or rejected	was chosen because	1 Switchboard was chosen because our prediction models were trained using another portion of the corpus.
method	Reasons why a method was adopted or rejected	was chosen because	Logistic regression was chosen because it produces a model with high performance and results that are easily interpretable.
method	Reasons why a method was adopted or rejected	the advantages of	The advantages of the new formulation are summarized in Table 1.
method	Reasons why a method was adopted or rejected	the advantages of	This is one of the advantages of using semantically-enabled languages, such as SPARQL.
method	Reasons why a method was adopted or rejected	one advantage of	One advantage of the discriminative method is that it enables us to incorporate arbitrary features.
method	Reasons why a method was adopted or rejected	one advantage of	One advantage of this procedure is that the list of nearest-neighbors and the similarities in Eq.
method	Reasons why a method was adopted or rejected	one advantage of	One advantage of the RNN is that it considers the word order in the event expression, which can be important.
method	Reasons why a method was adopted or rejected	one advantage of	One advantage of the argument model is that it only requires a single distribution over categories for each binary tree.
method	Reasons why a method was adopted or rejected	another advantage of	Another advantage of this structure is that it allows us to find the ‘hidden fragments’.
method	Reasons why a method was adopted or rejected	another advantage of	Another advantage of the discriminative tagger is its relatively good prediction power of the longer-distance dependencies.
method	Reasons why a method was adopted or rejected	have a number of advantages	For these applications, empirically estimated models have a number of advantages over handcrafted models such as online versions of bilingual dictionaries.
method	Reasons why a method was adopted or rejected	have a number of advantages	As we will show, Sequential Monte Carlo (SMC) algorithms have a number of advantages in this setting: they permit the efficient computation of both the outer and inner expectations, they are trivially parallelizable, and the number of samples provides an intuitive tuning tradeoff between accuracy and speed.
method	Reasons why a method was adopted or rejected	was chosen to	The data split was chosen to have minimal overlap between discriminant features.
method	Reasons why a method was adopted or rejected	was chosen to	The cutoff of 20% was chosen to allow a few variations for most phones.
method	Reasons why a method was adopted or rejected	was adopted to	After an initial pilot annotation study, the following annotation policy was adopted to overcome common disagreements: (1) When the argument is a noun and it is part of a definite description then include the entire definite description.
method	Reasons why a method was adopted or rejected	the main disadvantage of	However, the main disadvantage of this approach to estimate interlingual text similarity is that it strongly relies on the availability of a multilingual lexical resource.
method	Reasons why a method was adopted or rejected	the main disadvantage of	The main disadvantage of DCCA is its inability to support more than two views, and to learn conditioned on an additional shared view, which is why we introduce Deep Partial CCA.
method	Reasons why a method was adopted or rejected	the main disadvantage of	The main disadvantage of simple concatenation is that word embeddings are commonly used to initialize words in DNN systems; thus, the high-dimensionality of concatenated embeddings causes a great increase in training parameters.
method	Using methods used in past work	according to the procedure	Afterwards, according to the procedure proposed in (CITE-p-14-3-7), the domain-dependent logic expressions are generated in (d).
method	Using methods used in past work	using the same method as	First, a Japanese lexical substitution dataset was constructed using the same method as CITE-p-22-3-1.
method	Using methods used in past work	using the same method as	In this paper, the distortion probability in equation (2) is estimated during decoding, using the same method as described in Pharaoh (CITE-p-21-1-10).
method	Using methods used in past work	using the same method as	For each set, we assign labels to the extracted subtrees according to their frequencies by using the same method as that of CITE-p-28-1-4.
method	Using methods used in past work	based on * proposed by	This procedure is based on the WSD algorithm proposed by CITE-p-8-1-1.
method	Using methods used in past work	based on * proposed by	Our CNN implementation is based on the architecture proposed by CITE-p-12-1-4.
method	Using methods used in past work	by adapting	Model 0 can be parsed by adapting standard top-down or bottom-up chart parsing techniques.
method	Characteristics of samples or data	was divided into	For processing purposes, the corpus was divided into 3500 segments.
method	Characteristics of samples or data	was divided into	The data was divided into training, development and testing sets
method	Characteristics of samples or data	was divided into	The corpus was divided into training (75%) and testing (25%) sets.
method	Characteristics of samples or data	was divided into	The EPSaT corpus was divided into training (90%) and testing (10%) sets.
method	Characteristics of samples or data	were recruited from	Participants in our study were recruited from introductory undergraduate courses in psychology and computer science at the University of Central Florida.
method	Characteristics of samples or data	were recruited from	The participants were recruited from the Gothenburg MCI study, which is a large longitudinal study on mild cognitive impairment (CITE-p-17-5-7).
method	Characteristics of samples or data	were recruited from	The first dataset called LabWriting consists of 93 patients with schizophrenia who were recruited from sites in both Washington, D.C. and New York City.
method	Characteristics of samples or data	were recruited for	All data was annotated by 22 undergraduate and graduate students in various disciplines who were recruited for the task.
method	Characteristics of samples or data	over half	All the meetings in the AMI corpus are spoken in English, but over half the participants are nonnative speakers.
method	Characteristics of samples or data	over half	Slightly over half of the definitions have a length of 5–16 words; 75% have lengths between 3 and 23 words.
method	Characteristics of samples or data	met the criteria	No children met the criteria for a language impairment, and there were no significant between-group differences in age or full-scale IQ.
method	Characteristics of samples or data	met the criteria	None of the children in this study met the criteria for a language impairment, and there were no significant between-group differences in age (mean=6.4) or full-scale IQ (mean=114).
method	Characteristics of samples or data	met the criteria	None of the participants analyzed here met the criteria for language impairment, and the two groups were selected so that there were no statistically significant differences (via two-tailed t-test) between the groups in chronological age, verbal IQ, and full scale IQ.
method	Characteristics of samples or data	were included in	For each concept, the preferred term as well as the synonyms were included in the dictionary.
method	Characteristics of samples or data	were included in	Only users with at least two positive annotations were included in the final group of diagnosed users.
method	Characteristics of samples or data	were included in	Only wordforms that did not appear in the first gold standard were included in the second one.
method	Characteristics of samples or data	were divided into	The 79 subcategories were divided into training and testing segments.
method	Characteristics of samples or data	were divided into	Based on these assessments, the participants were divided into groups for each SUD type.
method	Characteristics of samples or data	were divided into	They were divided into four groups, which received 1, 2, 4 or 8 sets of words.
method	Criteria for selection	criteria for selecting	We established the following criteria for selecting textbooks and texts:
method	Criteria for selection	criteria for selecting	The criteria for selecting the next candidate sentence to annotate can then be described as: MATH-p-9-9-0 where MATH-p-9-11-0
method	Criteria for selection	only included in	These features were only included in our second run yiGou-midbaitu.
method	Criteria for selection	inclusion criteria	Of these, 326 studies complied with our inclusion criteria representing a total of 972 agreement indices.
method	Criteria for selection	inclusion criteria	Inclusion criteria for the control group were elderlies with no cognitive deficits and preservation of functional capacity in everyday life.
method	Criteria for selection	selected * on the basis of	These hashtags were selected on the basis of a nearest-neighbor search of the word embedding space.
method	Criteria for selection	selected * on the basis of	A larger set of Arabic Wikipedia articles, selected on the basis of quality heuristics, serves as unlabeled data for semisupervised learning.
method	Criteria for selection	selected * on the basis of	The predictors described above were selected for inclusion in a larger ensemble on the basis of their performance on the development set.
method	Criteria for selection	selected * on the basis of	The verbs were selected from Levin's classes on the basis of our intuitive judgment that they are likely to be used with sufficient frequency to be found in the corpus we had available.
method	Criteria for selection	was drawn from	The choice of related pairs in this dataset was drawn from VCL in the following way.
method	Criteria for selection	was drawn from	It was drawn from the top of the K&F list by the GETBASES procedure described below.
method	Description of the process	in order to identify	Keywords are used both in order to identify thematically relevant tweets and also targets.
method	Description of the process	in order to identify	In order to identify such terms, we first extract all content terms from the query.
method	Description of the process	in order to understand	In order to understand the temporal nature of healthcare data, we need to develop deep learning models whose parameters gets incrementally updated with time.
method	Description of the process	in order to understand	In order to understand the interaction among different component models, we conducted an ablation study by iteratively removing one model from the final combination.
method	Description of the process	in order to establish	We derived the test set from the user set in order to establish accuracies of our model over the application domain.
method	Description of the process	in order to establish	First the smaller corpus was annotated by the two main coders in collaboration in order to establish annotating policies in unclear cases.
method	Description of the process	in order to establish	In order to establish whether distributions differ significantly two different levels of significance were employed, depending on the number of pairwise comparisons performed.
method	Description of the process	in order to measure	In order to measure the semantic similarity between tweets, rather than isolated words, we needed a way to obtain vector representations of documents.
method	Description of the process	in order to determine	In order to determine the strength of supervision more dynamically, we introduce the adversarial learning.
method	Description of the process	in order to determine	In order to determine what these words are, we use the Stanford Dependencies Parser 1 .
method	Description of the process	in order to determine	In order to determine the most probable phrase combination in network structure, heuristic rules axe applied.
method	Description of the process	in order to control	In order to control for this a bound on minimum pronunciation length can be utilized.
method	Description of the process	in order to control	In order to control the quantity and quality of mined SSRs, a threshold minconf was introduced.
method	Description of the process	in order to assess	In order to assess annotation consistency, the same annotators re-annotated a random sample consisting of 30 reviews.
method	Description of the process	in order to assess	In order to assess the quality of the guidelines and the annotation, we conducted an inter-annotator agreement study.
method	Description of the process	in order to assess	In order to assess the contribution of each group to the overall system performance, we performed a feature ablation experiment.
method	Description of the process	to see if	Experts are consulted to see if a candidate is a true erroneous collocation.
method	Description of the process	to see if	The experts could access the premises to see if unclear references can be resolved.
method	Description of the process	to see if	Then the predicted agenda is checked to see if it contains any correct item.
method	Description of the process	to enable	Furthermore, we use a fixed random seed to enable replicability.
method	Description of the process	to increase	To increase their significance we double their raw count values.
method	Description of the process	to compare	Two separate tests were done, one to compare the means for each student individually, and one to compare the means across all students.
method	Description of the process	to compare	To compare with prior work, we use different experimental settings.
method	Description of the process	to compare	We also used a random forest classifier to compare results.
method	Description of the process	to prevent	This is to prevent fatigue over a period of time.
method	Description of the process	to prevent	The input order is randomized, to prevent spurious order effects.
method	Description of the process	to prevent	After that, a dropout layer is applied to prevent overfitting.
method	Description of the process	in order to remove	Once a phrase pattern graph has been created, we prune the graph in order to remove the redundant nodes.
method	Description of the process	in order to remove	We cleaned the corpus by applying a language detection tool (langdetect 2 ) to each sentence, in order to remove sentences which are too noisy.
method	Description of the process	were sent	Furthermore the recognized disorder concepts were sent to MetaMap (CITE-p-16-1-0) to look for their corresponding CUIs for generating normalized results.
method	Description of the process	were sent	These high-level task descriptions were sent to a crowdsourcing platform (CrowdFlower), in which workers were requested to express in natural language the commands which entail the scenario descriptions.
method	Description of the process	were sent	Third, a subset of the resulting sentences were sent to a validation task aimed at providing a highly reliable set of annotations over the same data, and at identifying areas of inferential uncertainty.
method	Description of the process	were normalised	All feature values were normalised so they were between 0 and 1.
method	Description of the process	were normalised	Note that all species words (e.g., Drosophila) were normalised to “SPECIESWORD”, and entities (e.g., Kip3) to “ENTITY”, which not only reduces the noise in the feature set, but also makes the model more species-generic.
method	Description of the process	was obtained from	For our experiments, the text was obtained from MEDLINE 2001 2 .
method	Description of the process	was obtained from	Approval to analyze the dataset was obtained from the Stanford IRB.
method	Description of the process	was obtained from	The dataset was obtained from a previous study conducted by the authors.
method	Description of the process	were administered	Six different surveys, each including approximately 50 stimulus words, were administered for each region.
method	Description of the process	were generated	The pronunciations were generated using CMU Dictionary and later manually corrected.
method	Description of the process	were generated	Training and test data instances were generated from our corpus as follows.
method	Description of the process	were generated	Negative examples were generated by randomly shuffling the original set of 1385 pairs.
method	Description of the process	were collected	Tweets were collected that contained reference to a temporal duration.
method	Description of the process	were collected	In total, over 10,000 commands were collected through the game.
method	Description of the process	were run	Our tests were run without any selection of a subject area.
method	Description of the process	were run	For supertagging, experiments were run with the standard splits of CCGbank.
method	Description of the process	were completed	Once these games were completed, we prioritized ordering based on object category to include a comprehensive range of objects.
method	Description of the process	were completed	The model parameters were completed with the estimation of the global normalization = constant MATH-w-3-13-5-14 .
method	Description of the process	were completed	Five grids for the same paragraph were completed by five different Turkers, with average pairwise inter-annotator agreement of 0.67.
method	Description of the process	were taken from	English words were taken from the January 2017 Wikipedia dump.
method	Description of the process	were taken from	All unigrams, bigrams, and trigrams were taken from each response.
method	Description of the process	was set at	The reward was set at $0.10 per translation, or roughly $0.005 per word.
method	Description of the process	was set at	The threshold was set at 200 words of automatically scraped body text of a linked document.
method	Description of the process	was set at	The number of latent dimensions for the SVD-reduced space was set at 300 after testing the performance using 300, 600 and 900 latent dimensions.
method	Description of the process	were performed	The experiments were performed on an i5, 2.8 GHz processor.
method	Description of the process	were performed	All annotations were performed by two people working in a team.
method	Description of the process	were identified	Seven possible types of relationships between TREATMENT and DISEASE were identified.
method	Description of the process	were identified	Paragraphs were identified based on formatting information available in the articles.
method	Description of the process	were identified	Negation relations were identified using the output of the dependency parser.
method	Description of the process	were gathered	Web queries were gathered from online sources of real-world queries.
method	Description of the process	were gathered	The human ratings were gathered using the Magnitude Estimation technique (CITE-p-13-1-0).
method	Description of the process	were coded	Questions were coded simply by the presence of question marks.
method	Description of the process	were coded	The sentences were coded by five crowdsourced workers and one expert.
method	Description of the process	were searched	Further, online reference lists of projects and authors concerned with manual annotations were searched.
method	Description of the process	were searched	Using the above approach for Chinese-English, 185 candidate sites were searched from the domain hk.
method	Description of the process	the first step was to	Articles and summaries are paired by document, so the first step was to perform sentence alignment.
method	Description of the process	the first step was to	The first step was to obtain the tweet content and forming the instances of the training set.
method	Description of the process	the first step was to	The first step was to identify the languages which are syntactically related to the surprise languages and whose treebanks are in Universal Dependency corpus.
method	Description of the process	prior to	These statistics are calculated prior to consolidating multiple annotators’ work.
method	Description of the process	prior to	Dropout is then applied to these vectors prior to classification.
method	Description of the process	prior to	Compound splitting is performed on the training corpus, prior to training.
method	Description of the process	prior to	Prior to learning, the training corpus undergoes several steps of preprocessing.
method	Description of the process	after training	After training, the preference classifier can be used to resolve anaphors.
method	Description of the process	after training	After training, we can apply the resulting model to resolve AZPs.
method	Description of the process	after training	After training, the learned embedding matrices are ready to be used.
method	Description of the process	after collection	After collection, subjects who are obvious spammers or did not follow instructions are manually filtered.
method	Description of the process	after collection	After collection, we get a set of instances MATH-w-6-1-2-101 with different document-topic distributions for each bilingual term pair.
method	Description of the process	after testing	The way of combining the two similarity functions has been determined empirically after testing several other ways of combining them.
method	Description of the process	after testing	Hyperparameter tuning is done on the validation set and the results are reported after testing on a held out test set.
method	Description of the process	after testing	The number of latent dimensions for the SVD-reduced space was set at 300 after testing the performance using 300, 600 and 900 latent dimensions.
method	Description of the process	were asked to	Users were asked to answer questions like “Do you smoke?”
method	Description of the process	were asked to	Judges were asked to rank sentences from best to worse.
method	Description of the process	were asked to	They then were asked to reach a consensus about correctness.
method	Description of the process	were asked to	The judges were asked to draw lines between matching sentences.
method	Description of the process	were asked to	The human subjects were asked to summaries to improve their quality.
method	Description of the process	was carried out	An identification task similar to Experiment 1 was carried out.
method	Description of the process	was carried out	This checking process was carried out with the training set.
method	Description of the process	was carried out	This removal was carried out on both the transcripts and audio.
method	Description of the process	it was necessary to	For this reason, it was necessary to employ validation in training.
method	Description of the process	it was necessary to	Accordingly, it was necessary to identify the closest match possible for each of the three parsing systems in order to encode parse tree paths for each.
method	Description of the process	were then	The manual translations were then compared against the automatic translations.
method	Description of the process	were then	Each of the clusters were then encoded using convolutional filters.
method	Description of the process	were then	Users were then asked to correct any mistakes they produced.
method	Description of the process	were then	The remaining expressions were then combined with the potential anaphor.
method	Description of the process	were then	11 models were then interpolated to create one language model.
method	Description of the process	was then	An LR classifier was then trained over the labeled sentences.
method	Description of the process	and then	We first discuss the feature set and then the algorithm.
method	Description of the process	and then	And then we describe the method of automatically labeling data.
method	Description of the process	and then	We begin with a review and then introduce the SCTM.
method	Description of the process	finally	Finally, the node pair probability is modeled as Pr(𝑁 𝑚𝐹 , 𝑁 𝑖𝐸 ) = Pr(𝑁 𝑚𝐹 . 𝑡, 𝑁 𝑖𝐸 
method	Description of the process	finally	Finally, we randomly pull 200 tweets for each identified user.
method	Description of the process	was calculated using	The coreference feature value was calculated using clusters of coreferential entities.
method	Description of the process	was calculated using	The transitive closure was calculated using the Warshall algorithm (CITE-p-13-1-0).
method	Description of the process	was calculated using	In other cases, chunk-to-chunk similarity was calculated using optimal word alignment method.
method	Description of the process	was calculated using	The similarity of the vectors was calculated using both cosine similarity and Euclidean distance.
